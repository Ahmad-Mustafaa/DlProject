{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import tkinter as tk\n",
    "from tkinter import simpledialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "face_net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'res10_300x300_ssd_iter_140000.caffemodel')\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "# Load face embedding model\n",
    "embed_model = cv2.dnn.readNetFromTorch('C:\\\\Users\\\\amodarling\\\\Downloads\\\\openface.nn4.small2.v1.t7')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the webcam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# def detect_face(frame):\n",
    "#     (h, w) = frame.shape[:2]\n",
    "#     blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n",
    "#                                  (300, 300), (104.0, 177.0, 123.0))\n",
    "#     face_net.setInput(blob)\n",
    "#     detections = face_net.forward()\n",
    "#     face_boxes = []\n",
    "\n",
    "#     for i in range(detections.shape[2]):\n",
    "#         confidence = detections[0, 0, i, 2]\n",
    "#         if confidence > 0.5:\n",
    "#             box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "#             (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "#             face_boxes.append((startX, startY, endX, endY))\n",
    "    \n",
    "#     return face_boxes\n",
    "\n",
    "# def is_blinking(eye_aspect_ratio, threshold=0.2):\n",
    "#     return eye_aspect_ratio < threshold\n",
    "\n",
    "# def eye_aspect_ratio(eye):\n",
    "#     A = np.linalg.norm(eye[1] - eye[5])\n",
    "#     B = np.linalg.norm(eye[2] - eye[4])\n",
    "#     C = np.linalg.norm(eye[0] - eye[3])\n",
    "#     ear = (A + B) / (2.0 * C)\n",
    "#     return ear\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "    \n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     face_boxes = detect_face(frame)\n",
    "\n",
    "#     for (startX, startY, endX, endY) in face_boxes:\n",
    "#         face = frame[startX:endX, startY:endY]\n",
    "#         cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "#         # Add eye detection here for blink detection\n",
    "\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the pre-trained model for face detection\n",
    "# face_net = cv2.dnn.readNetFromCaffe('deploy.prototxt', 'res10_300x300_ssd_iter_140000.caffemodel')\n",
    "\n",
    "# # Load Haar cascade for eye detection\n",
    "# eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# # Function to detect faces using OpenCV's DNN module\n",
    "# def detect_face(frame):\n",
    "#     (h, w) = frame.shape[:2]\n",
    "#     blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "#     face_net.setInput(blob)\n",
    "#     detections = face_net.forward()\n",
    "#     face_boxes = []\n",
    "\n",
    "#     for i in range(detections.shape[2]):\n",
    "#         confidence = detections[0, 0, i, 2]\n",
    "#         if confidence > 0.5:\n",
    "#             box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "#             (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "#             face_boxes.append((startX, startY, endX, endY))\n",
    "    \n",
    "#     return face_boxes\n",
    "\n",
    "# # Function to calculate the eye aspect ratio (EAR)\n",
    "# def eye_aspect_ratio(eye):\n",
    "#     A = np.linalg.norm(eye[1] - eye[5])\n",
    "#     B = np.linalg.norm(eye[2] - eye[4])\n",
    "#     C = np.linalg.norm(eye[0] - eye[3])\n",
    "#     ear = (A + B) / (2.0 * C)\n",
    "#     return ear\n",
    "\n",
    "# # Function to determine if the eyes are blinking\n",
    "# def is_blinking(ear, threshold=0.2):\n",
    "#     return ear < threshold\n",
    "\n",
    "# # Initialize the webcam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     face_boxes = detect_face(frame)\n",
    "\n",
    "#     for (startX, startY, endX, endY) in face_boxes:\n",
    "#         cv2.rectangle(frame, (startX, startY), (endX, endY), (255, 0, 0), 2)\n",
    "#         roi_gray = gray[startY:endY, startX:endX]\n",
    "#         roi_color = frame[startY:endY, startX:endX]\n",
    "\n",
    "#         eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#         eye_aspects = []\n",
    "\n",
    "#         for (ex, ey, ew, eh) in eyes:\n",
    "#             eye_center = (ex + ew // 2, ey + eh // 2)\n",
    "#             radius = int(round((ew + eh) * 0.25))\n",
    "#             eye_coords = np.array([\n",
    "#                 (eye_center[0] - radius, eye_center[1] - radius),\n",
    "#                 (eye_center[0] - radius, eye_center[1]),\n",
    "#                 (eye_center[0] - radius, eye_center[1] + radius),\n",
    "#                 (eye_center[0] + radius, eye_center[1] - radius),\n",
    "#                 (eye_center[0] + radius, eye_center[1]),\n",
    "#                 (eye_center[0] + radius, eye_center[1] + radius),\n",
    "#             ], np.int32)\n",
    "#             eye_aspects.append(eye_aspect_ratio(eye_coords))\n",
    "\n",
    "#             cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "\n",
    "#         # Check if any eye is blinking\n",
    "#         if any(is_blinking(ear) for ear in eye_aspects):\n",
    "#             cv2.putText(frame, \"Blink Detected\", (startX, startY - 10),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# Directory to save known faces\n",
    "KNOWN_FACES_DIR = 'known_faces'\n",
    "os.makedirs(KNOWN_FACES_DIR, exist_ok=True)\n",
    "\n",
    "# Load known faces and names from a file\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "    if os.path.exists('known_faces.pkl'):\n",
    "        with open('known_faces.pkl', 'rb') as f:\n",
    "            known_faces, known_names = pickle.load(f)\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Save known faces and names to a file\n",
    "def save_known_faces(known_faces, known_names):\n",
    "    with open('known_faces.pkl', 'wb') as f:\n",
    "        pickle.dump((known_faces, known_names), f)\n",
    "\n",
    "known_faces, known_names = load_known_faces()\n",
    "\n",
    "# Function to detect faces using OpenCV's DNN module\n",
    "def detect_faces(frame):\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    face_net.setInput(blob)\n",
    "    detections = face_net.forward()\n",
    "    face_boxes = []\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            face_boxes.append((startX, startY, endX, endY))\n",
    "    \n",
    "    return face_boxes\n",
    "\n",
    "# Function to get face embeddings\n",
    "def get_face_embedding(model, face_image):\n",
    "    face_blob = cv2.dnn.blobFromImage(face_image, 1.0/255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "    model.setInput(face_blob)\n",
    "    return model.forward()\n",
    "\n",
    "# Function to register a new face\n",
    "def register_face(face_encoding, face_image):\n",
    "    name = input(\"Enter the name for the detected face: \")\n",
    "    known_faces.append(face_encoding)\n",
    "    known_names.append(name)\n",
    "    save_known_faces(known_faces, known_names)\n",
    "    face_image_path = os.path.join(KNOWN_FACES_DIR, f\"{name}.jpg\")\n",
    "    cv2.imwrite(face_image_path, face_image)\n",
    "    print(f\"Registered new face as {name} and saved to database.\")\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_boxes = detect_faces(frame)\n",
    "\n",
    "    for (startX, startY, endX, endY) in face_boxes:\n",
    "        face = frame[startY:endY, startX:endX]\n",
    "        face_embedding = get_face_embedding(embed_model, face)\n",
    "\n",
    "        matches = [np.linalg.norm(face_embedding - known_face) for known_face in known_faces]\n",
    "        min_distance = min(matches) if matches else None\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        if min_distance is not None and min_distance < 0.6:  # Threshold for matching\n",
    "            match_index = matches.index(min_distance)\n",
    "            name = known_names[match_index]\n",
    "        else:\n",
    "            register_face(face_embedding, face)\n",
    "            name = known_names[-1]\n",
    "\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, name, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name input canceled.\n",
      "Registered new face as ahmad and saved to database.\n",
      "Name input canceled.\n",
      "Registered new face as saim and saved to database.\n",
      "Registered new face as saim and saved to database.\n",
      "Name input canceled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Directory to save known faces\n",
    "KNOWN_FACES_DIR = 'known_faces'\n",
    "os.makedirs(KNOWN_FACES_DIR, exist_ok=True)\n",
    "\n",
    "# Load known faces and names from a file\n",
    "def load_known_faces():\n",
    "    known_faces = []\n",
    "    known_names = []\n",
    "    if os.path.exists('known_faces.pkl'):\n",
    "        with open('known_faces.pkl', 'rb') as f:\n",
    "            known_faces, known_names = pickle.load(f)\n",
    "    return known_faces, known_names\n",
    "\n",
    "# Save known faces and names to a file\n",
    "def save_known_faces(known_faces, known_names):\n",
    "    with open('known_faces.pkl', 'wb') as f:\n",
    "        pickle.dump((known_faces, known_names), f)\n",
    "\n",
    "known_faces, known_names = load_known_faces()\n",
    "\n",
    "# Function to detect faces using OpenCV's DNN module\n",
    "def detect_faces(frame):\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    face_net.setInput(blob)\n",
    "    detections = face_net.forward()\n",
    "    face_boxes = []\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            face_boxes.append((startX, startY, endX, endY))\n",
    "    \n",
    "    return face_boxes\n",
    "\n",
    "# Function to get face embeddings\n",
    "def get_face_embedding(model, face_image):\n",
    "    face_blob = cv2.dnn.blobFromImage(face_image, 1.0/255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "    model.setInput(face_blob)\n",
    "    return model.forward()\n",
    "\n",
    "# Function to register a new face\n",
    "def register_face(face_encoding, face_image):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    name = simpledialog.askstring(\"Input\", \"Enter the name for the detected face:\")\n",
    "    if name is not None:\n",
    "        known_faces.append(face_encoding)\n",
    "        known_names.append(name)\n",
    "        save_known_faces(known_faces, known_names)\n",
    "        face_image_path = os.path.join(KNOWN_FACES_DIR, f\"{name}.jpg\")\n",
    "        cv2.imwrite(face_image_path, face_image)\n",
    "        print(f\"Registered new face as {name} and saved to database.\")\n",
    "    else:\n",
    "        print(\"Name input canceled.\")\n",
    "    root.destroy()\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "capture_image = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_boxes = detect_faces(frame)\n",
    "\n",
    "    for (startX, startY, endX, endY) in face_boxes:\n",
    "        face = frame[startY:endY, startX:endX]\n",
    "        face_embedding = get_face_embedding(embed_model, face)\n",
    "\n",
    "        matches = [np.linalg.norm(face_embedding - known_face) for known_face in known_faces]\n",
    "        min_distance = min(matches) if matches else None\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        if min_distance is not None and min_distance < 0.7:  # Threshold for matching\n",
    "            match_index = matches.index(min_distance)\n",
    "            name = known_names[match_index]\n",
    "        else:\n",
    "            if capture_image:\n",
    "                register_face(face_embedding, face)\n",
    "                capture_image = False\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, name, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('a'):\n",
    "        capture_image = True\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
